{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ColModernVBERT for Visual Document Retrieval\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harpreetsahota204/colmodernvbert/blob/main/colmodernvbert_for_Visual_Document_Retrieval.ipynb)\n",
        "\n",
        "This notebook demonstrates how to use **ColModernVBERT** - a multi-vector vision-language model for fine-grained document retrieval and zero-shot classification - integrated as a FiftyOne Zoo Model.\n",
        "\n",
        "## What is ColModernVBERT?\n",
        "\n",
        "ColModernVBERT is a state-of-the-art multi-vector vision-language model that:\n",
        "- Generates **~884 vectors per image** (128-dim each) for fine-grained representation\n",
        "- Uses **ColBERT-style late interaction** (MaxSim scoring) for accurate matching\n",
        "- Supports both **similarity search** (pooled embeddings) and **zero-shot classification** (full multi-vectors)\n",
        "- Excels at **visual document understanding** tasks\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "1. ‚úÖ Load document datasets from Hugging Face\n",
        "2. ‚úÖ Register and use ColModernVBERT as a FiftyOne Zoo Model\n",
        "3. ‚úÖ Compute multi-vector embeddings with different pooling strategies\n",
        "4. ‚úÖ Visualize document embeddings with UMAP\n",
        "5. ‚úÖ Build text-to-image similarity search\n",
        "6. ‚úÖ Perform zero-shot document classification\n",
        "\n",
        "---\n",
        "\n",
        "**Note**: This notebook requires a GPU runtime. In Colab, go to **Runtime > Change runtime type > GPU (T4, A100, etc.)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Installation\n",
        "\n",
        "First, let's install the required dependencies:\n",
        "- **FiftyOne**: For dataset management and visualization\n",
        "- **UMAP**: For embedding visualization\n",
        "- **ColPali Engine**: The backend library that provides ColModernVBERT implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuBn_wX6YJWp"
      },
      "outputs": [],
      "source": [
        "!pip install fiftyone umap-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install the ColPali Engine from the vbert branch (provides ColModernVBERT implementation):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB_SYYM0wy9z"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/illuin-tech/colpali.git@vbert#egg=colpali-engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Load Dataset\n",
        "\n",
        "We'll use the **document-haystack-10pages** dataset from Hugging Face, which contains document images designed for retrieval tasks.\n",
        "\n",
        "This dataset simulates a \"needle in a haystack\" scenario where you need to find specific documents containing particular text or information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nARIPQR_xX6C"
      },
      "outputs": [],
      "source": [
        "import fiftyone as fo\n",
        "from fiftyone.utils.huggingface import load_from_hub\n",
        "\n",
        "# Load the dataset\n",
        "# Note: other available arguments include 'max_samples', etc\n",
        "dataset = load_from_hub(\n",
        "    \"Voxel51/document-haystack-10pages\",\n",
        "    overwrite=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Register ColModernVBERT Zoo Model\n",
        "\n",
        "FiftyOne's Zoo Model system allows you to register remote model sources. Let's register the ColModernVBERT repository:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBb_GkrTMB8u"
      },
      "outputs": [],
      "source": [
        "import fiftyone.zoo as foz\n",
        "\n",
        "foz.register_zoo_model_source(\n",
        "    \"https://github.com/harpreetsahota204/colmodernvbert\",\n",
        "    overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download the model weights and configuration:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm8Hvy_2ak9d"
      },
      "outputs": [],
      "source": [
        "foz.download_zoo_model(\n",
        "    \"https://github.com/harpreetsahota204/colmodernvbert\",\n",
        "    model_name=\"ModernVBERT/colmodernvbert\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Load the Model\n",
        "\n",
        "Now let's load ColModernVBERT with a specific pooling strategy.\n",
        "\n",
        "### Pooling Strategies\n",
        "\n",
        "- **`mean`**: Averages all vectors ‚Üí best for holistic semantic matching\n",
        "- **`max`**: Takes maximum values ‚Üí best for keyword-based search\n",
        "\n",
        "For document retrieval, both work well. We'll use **`max`** pooling to focus on finding specific content matches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7m7NutPN5nd"
      },
      "outputs": [],
      "source": [
        "import fiftyone.zoo as foz\n",
        "\n",
        "model = foz.load_zoo_model(\n",
        "    \"ModernVBERT/colmodernvbert\",\n",
        "    pooling_strategy=\"max\" #could also choose mean\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Compute Embeddings\n",
        "\n",
        "Now we'll compute embeddings for all documents in the dataset.\n",
        "\n",
        "### What's Happening Under the Hood?\n",
        "1. Each image is processed by ColModernVBERT ‚Üí generates **~884 vectors** (128-dim each)\n",
        "2. These multi-vectors are **pooled** (using max pooling) ‚Üí single **128-dim embedding**\n",
        "3. The pooled embeddings are stored in FiftyOne for efficient similarity search\n",
        "\n",
        "This gives us the best of both worlds: fine-grained multi-vector representation compressed into efficient single vectors for retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNMV0a2ZN5rg"
      },
      "outputs": [],
      "source": [
        "dataset.compute_embeddings(\n",
        "    model=model,\n",
        "    embeddings_field=\"colmodernbert_embeddings\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's verify the embedding shape - it should be a 128-dimensional vector:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnAHsGaQWXnR"
      },
      "outputs": [],
      "source": [
        "dataset.first()['colmodernbert_embeddings'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üó∫Ô∏è Visualize Embeddings with UMAP\n",
        "\n",
        "Let's create a 2D visualization of our document embeddings using UMAP (Uniform Manifold Approximation and Projection).\n",
        "\n",
        "This will help us:\n",
        "- See how documents cluster in the embedding space\n",
        "- Identify similar documents visually\n",
        "- Understand the semantic structure of our dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBA63hVFN5vy"
      },
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "results = fob.compute_visualization(\n",
        "    dataset,\n",
        "    embeddings=\"colmodernbert_embeddings\",\n",
        "    method=\"umap\",\n",
        "    brain_key=\"colmodernbert_viz\",\n",
        "    num_dims=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Build Text-to-Image Similarity Index\n",
        "\n",
        "Now let's build a similarity index that allows us to search for documents using text queries.\n",
        "\n",
        "This index enables:\n",
        "- **Text-to-image search**: Find documents matching text descriptions\n",
        "- **Image-to-image search**: Find similar documents\n",
        "- **Efficient k-NN lookups**: Fast retrieval at scale\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6HwrfM6N5z9"
      },
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "text_img_index = fob.compute_similarity(\n",
        "    dataset,\n",
        "    model= \"ModernVBERT/colmodernvbert\",\n",
        "    embeddings_field=\"colmodernbert_embeddings\",\n",
        "    brain_key=\"colmodernbert_sim\",\n",
        "    model_kwargs={\"pooling_strategy\": \"max\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Search with Text Queries\n",
        "\n",
        "Let's extract the \"needle texts\" (target content) from the dataset and use them as queries to find matching documents.\n",
        "\n",
        "For each query, we'll retrieve the **top 3** most similar documents:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqf0byCDN53m"
      },
      "outputs": [],
      "source": [
        "queries = dataset.distinct(\"needle_texts\")\n",
        "\n",
        "sims = text_img_index.sort_by_similarity(\n",
        "    queries,\n",
        "    k=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Zero-Shot Classification\n",
        "\n",
        "Now let's use ColModernVBERT for zero-shot classification!\n",
        "\n",
        "Instead of pooled embeddings, this mode uses the **full multi-vectors** with **MaxSim scoring** for the highest accuracy.\n",
        "\n",
        "### How MaxSim Works\n",
        "1. Image ‚Üí ~884 vectors (128-dim each)\n",
        "2. Each text class ‚Üí ~13 vectors (128-dim each)\n",
        "3. For each text vector, find its max similarity with any image vector\n",
        "4. Sum these max similarities ‚Üí classification score\n",
        "\n",
        "This allows the model to match specific text tokens to relevant image regions!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the model's classes to our query texts (these become the classification labels):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4HEB5-EgH-2"
      },
      "outputs": [],
      "source": [
        "model.classes = queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply the model to classify all documents based on which query text they best match:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSspFEN4zztj"
      },
      "outputs": [],
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "\n",
        "dataset.apply_model(\n",
        "    model,\n",
        "    label_field=\"predictions\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine the predictions for a sample document:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cW5P4-99e4X"
      },
      "outputs": [],
      "source": [
        "dataset.first()['predictions']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé® Launch FiftyOne App\n",
        "\n",
        "Finally, let's launch the FiftyOne App to interactively explore our results!\n",
        "\n",
        "The app provides:\n",
        "- Visual browsing of documents\n",
        "- Interactive similarity search\n",
        "- Classification predictions overlay\n",
        "- UMAP embedding visualization\n",
        "- Filtering and sorting capabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXhzv0p0RcG-"
      },
      "outputs": [],
      "source": [
        "session=fo.launch_app(sims, auto=False)\n",
        "\n",
        "session.url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Summary\n",
        "\n",
        "‚úÖ Loaded a document dataset from Hugging Face  \n",
        "‚úÖ Registered ColModernVBERT as a FiftyOne Zoo Model  \n",
        "‚úÖ Computed 128-dimensional pooled embeddings from multi-vector representations  \n",
        "‚úÖ Created UMAP visualizations of document embeddings  \n",
        "‚úÖ Built a text-to-image similarity search index  \n",
        "‚úÖ Performed zero-shot classification using MaxSim scoring  \n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "**Multi-Vector Architecture**: ColModernVBERT generates ~884 vectors per image, enabling fine-grained region-to-text matching.\n",
        "\n",
        "**Dual-Mode Operation**:\n",
        "- **Retrieval mode**: Pooled 128-dim embeddings for efficient similarity search\n",
        "- **Classification mode**: Full multi-vectors with MaxSim for highest accuracy\n",
        "\n",
        "**Pooling Strategies**:\n",
        "- `mean`: Holistic semantic matching\n",
        "- `max`: Keyword-based search\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Try different classification tasks by changing `model.classes`\n",
        "- Experiment with custom text prompts\n",
        "- Compare `mean` vs `max` pooling strategies\n",
        "- Use the similarity index for custom text queries\n",
        "- Explore the FiftyOne App's interactive features\n",
        "\n",
        "### Resources\n",
        "\n",
        "- **Model**: [ModernVBERT/colmodernvbert](https://huggingface.co/ModernVBERT/colmodernvbert)\n",
        "- **Repository**: [github.com/harpreetsahota204/colmodernvbert](https://github.com/harpreetsahota204/colmodernvbert)\n",
        "- **Paper**: [ModernVBERT: Towards Smaller Visual Document Retrievers](https://arxiv.org/abs/2510.01149)\n",
        "- **FiftyOne Docs**: [docs.voxel51.com](https://docs.voxel51.com)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
